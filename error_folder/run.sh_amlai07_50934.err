wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: joanlafuente. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /export/fhome/amlai07/Adavanced_DP/wandb/run-20241120_193207-qsv7eeng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run baseline_proba
wandb: ‚≠êÔ∏è View project at https://wandb.ai/joanlafuente/Advanced_DP
wandb: üöÄ View run at https://wandb.ai/joanlafuente/Advanced_DP/runs/qsv7eeng
  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.03it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.74it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.70it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.52s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.52s/it]
Traceback (most recent call last):
  File "/fhome/amlai07/Adavanced_DP/main.py", line 37, in <module>
    model = baseline_train(model, train_loader, val_loader, test_loader, optimizer, criterion, device, config["training_params"]["epochs"])
  File "/export/fhome/amlai07/Adavanced_DP/src/utils/train_loops.py", line 165, in baseline_train
    generate_plot_practica(result_top1, result_top5, save_path)
  File "/export/fhome/amlai07/Adavanced_DP/src/utils/train_loops.py", line 188, in generate_plot_practica
    ax[0].barh(y_labels_top1, y_top1)
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 2760, in barh
    patches = self.bar(x=left, height=height, width=width, bottom=y,
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/__init__.py", line 1473, in inner
    return func(
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 2500, in bar
    self._process_unit_info(
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 2585, in _process_unit_info
    axis.update_units(data)
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/axis.py", line 1750, in update_units
    converter = munits.registry.get_converter(data)
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/units.py", line 190, in get_converter
    return self.get_converter(first)
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/units.py", line 167, in get_converter
    x = cbook._unpack_to_numpy(x)
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/matplotlib/cbook.py", line 2395, in _unpack_to_numpy
    xtmp = x.__array__()
  File "/fhome/amlai07/miniconda3/envs/AdvancedDP/lib/python3.10/site-packages/torch/_tensor.py", line 1149, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
